package com.chris.some.code.study.geektime.datastructureandalgorithm.algorithm;

/**
 * 数据结构是为算法服务的，算法要作用在特定的数据结构之上
 * <pre>
 *     数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树
 *     算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法
 *     学习技巧：
 *         1、边学边练，适度刷题
 *         2、多问、多思考、多互动
 *         3、打怪升级学习法
 *         4、知识需要沉淀
 * </pre>
 * 复杂度分析
 * <pre>
 *     时间、空间复杂度分析
 * </pre>
 * 一、时间复杂度
 * <p>
 * 1、什么是时间复杂度
 * <pre>
 *     1.1、数据结构和算法解决是"如何让计算机更快时间更省空间的解决问题"
 *     1.2、因此需要从执行时间和占用空间两个维度来评估数据结构和算法的性能
 *     1.3、分别用时间复杂度和空间复杂度两个概念来描述性能问题，二者统称为复杂度
 *     1.4、复杂度描述的是算法执行时间（或占用空间）与数据规模的增长关系
 * </pre>
 * 2、为什么进行复杂度分析
 * <pre>
 *     2.1、和性能测试相比，复杂度分析有不依赖执行环境、成本低、效率高、易操作、指导性强的特点
 *     2.2、掌握复杂度分析，将能编写出性能更优的代码，有利于降低系统开发和维护成本
 * </pre>
 * 3、如何进行复杂度分析
 * <p>
 * 3.1、大O复杂度表示法
 * <pre>
 *     3.1.1、来源：算法的执行时间与每行代码的执行次数成正比，用T(n) = O(f(n))表示，其中T(n)表示算法执行总时间，f(n)表示每行代码执行总次数，而n往往表示数据的规模
 *     3.1.2、特点：以时间复杂度为例，由于时间复杂度描述的是算法执行时间与数据规模的增长变化趋势，所以常量阶、低阶以及系数实际上对这种增长趋势不产决定性影响，所以在做时间复杂度分析时忽略这些项
 * </pre>
 * 3.2、复杂度分析法则
 * <pre>
 *     3.2.1、单段代码看高频：只关注循环执行次数最多的一段代码，比如循环
 *     3.2.2、多段代码取最大：总复杂度等于量级最大的那段代码的复杂度，比如一段代码中有单循环和多重循环，那么取多重循环的复杂度
 *     3.2.3、嵌套代码求乘积：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积，比如递归、多重循环等
 *     3.2.4、多个规模求加法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相加
 * </pre>
 * 4、常用的复杂度级别
 * <pre>
 *     4.1、多项式阶：随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。包括， O(1)（常数阶）、O(logn)（对数阶）、O(n)（线性阶）、O(nlogn)（线性对数阶）、O(n^2)（平方阶）、O(n^3)（立方阶）
 *     4.2、非多项式阶：随着数据规模的增长，算法的执行时间和空间占用暴增，这类算法性能极差。包括， O(2^n)（指数阶）、O(n!)（阶乘阶）
 * </pre>
 * 总结：
 * <pre>
 *     所有代码的执行时间T(n) 与每行代码的执行次数成正比. 即: 每行代码的执行次数越多,所有代码的执行时间就越长. 每行代码的执行次数越少,所有代码的执行时间就越短
 *     T(n) = O(f(n))
 *     T(n)代表代码的执行时间，f(n)表示每行代码执行的次数总和，O表示两者成正比
 * </pre>
 *
 * @author grt
 */
public class Complexity {

    public static void main(String[] args) {
    }

    /**
     * 每一行代码都执行着类似的操作：读元素-运算-写元素
     * <p>
     * 假设每行代码执行的时间都一样，为unit_time
     * 第2、3行代码分别需要1个unit_time的执行时间
     * 第4、5行都运行了n遍，所以需要 2n * unit_time 的执行时间
     * 所以这段代码总的执行时间就是 T(n) = (2n +2)*unit_time
     * <p>
     * 单段代码看高频：循环执行次数最多的是第4、5行，所以时间复杂度是O(n)
     */
    static int cal1(int n) {
        int sum = 0;
        int i = 1;
        for (; i <= n; ++i) {
            sum += i;
        }
        return sum;
    }

    /**
     * 第2行代码分别需要1个unit_time的执行时间
     * 第3行代码循环执行了n遍，需要 n * unit_time 的执行时间
     * 第4、5行代码循环执行了n^2遍，所以需要 2n^2 * unit_time 的执行时间
     * 所以这段代码总的执行时间就是 T(n) = (2n^2 + n +3)*unit_time
     */
    static int cal2(int n) {
        int sum = 0;
        for (int i = 0; i < n; i++) {
            for (int j = 0; j < n; j++) {
                sum += i * j;
            }
        }
        return sum;
    }

    /**
     * 第3、4行代码执行100遍，100 * unit_time
     * 第8、9行代码执行n遍，n * unit_time
     * 第13行代码执行n遍，第14、15行代码执行n^2遍，(n^2 + n) * unit_time，既 n^2 * unit_time
     * <p>
     * 多段代码取最大：量级最大的代码是第13、14、15行，所以时间复杂度是：O(n^2)
     * <pre>
     *     如果T1(n) = O(f(n))，T2(n) = O(g(n))
     *     T(n) = T1(n) + T2(n) = max(O(f(n)) , O(g(n))) = O(max(f(n) , g(n)))
     * </pre>
     */
    static int cal3(int n) {
        int sum1 = 0;
        for (int i = 0; i < 100; i++) {
            sum1 += i;
        }

        int sum2 = 0;
        for (int i = 0; i < n; i++) {
            sum2 += i;
        }

        int sum3 = 0;
        for (int i = 0; i < n; i++) {
            for (int j = 0; j < n; j++) {
                sum1 += i + j;
            }
        }

        return sum1 + sum2 + sum3;
    }

}
